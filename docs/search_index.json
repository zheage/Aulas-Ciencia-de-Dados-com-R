[["index.html", "CIÊNCIA DE DADOS COM LINGUAGEM R Sobre o autor", " CIÊNCIA DE DADOS COM LINGUAGEM R Richard Guilherme dos Santos Sobre o autor Bem vindo! Sou formado em Matemática pela UNESP e atualmente faço mestrado em estatística pelo programa PIPGEs. Já me perguntei diversas vezes em como toda a teoria de probabilidade, estatística, inferência e de aprendizado de máquina é utilizada na prática, para resolver problemas que me deixavam curioso ou até mesmo competições de programação. Este livro vem para resolver este tipo de problema que chamou tanto minha atenção no passado. "],["introdução.html", "Capítulo 1 Introdução", " Capítulo 1 Introdução Este livro tem como objetivo servir como guia para as aulas do curso Ciência de Dados com R. Nele apresentaremos os conceitos de: Estatística Básica: Nesta parte do curso abordaremos conceitos de estatística como variáveis, tipos de distribuições discretas e contínuas, medidas descritivas e distribuição normal. Manipulação de dados no R: Neste tópico serão abordados as principais formas de manipulação de dados utilizando a linguagem R, com ênfase nas bibliotecas dplyr e tidyr. Além disso, abordaremos a criação de gráficos pelo pacote ggplot2. Modelos de Regressão Linear: Parte final do curso, onde o aluno aprenderá sobre diagrama de dispersão, coeficiente de correlação linear, regressão linear simples, múltipla e regressão logística, ganhando a capacidade de começar a criar modelos utilizando a linguagem R. "],["introdução-ao-r.html", "Capítulo 2 Introdução ao R", " Capítulo 2 Introdução ao R Aqui introduziremos alguns comandos da linguagem R, onde utilizamos funções para realizar operações que vão desde leitura e manipulação de dados a operações matemáticas. Comecemos criando um vetor de números: x &lt;- c(1,3,2,5) # x = c(1,3,2,5) # Também podemos utilizar &quot;=&quot; para atribuir variáveis x ## [1] 1 3 2 5 O comando acima combina os números 1,3,2 e 5 em um vetor de números e os salva em um objeto denominado x. Escrevemos x para recebermos os atributos do vetor. A partir disto podemos utilizar outras funções para calcularmos informações destes atributos, como o tamanho de um vetor: length(x) ## [1] 4 sua média: mean(x) ## [1] 2.75 também podemos realizar operações entre os vetores: a &lt;- c(1,2,3) b &lt;- c(2,3,4) a+b ## [1] 3 5 7 Há outros tipos de objetos que podem ser criados quando trabalhamos com R. Dentre os mais importantes para manipulação de dados estão as matrizes: mat = matrix(data = c(1,2,3,4), nrow = 2, ncol = 2, byrow = TRUE) mat ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 muitos devem já estar familiarizados com estas. A linguagem R fornece as mais diversas operações entre matrizes: a = matrix(data = 1:9, nrow = 3, ncol = 3) b = matrix(data = 1:9, nrow = 3, ncol = 3, byrow = T) # a + b # Soma de matrizes # a * b # Multiplicação dos elementos das matrizes termo a termo # a %*% b # Multiplicação de matrizes # t(a) # Transposta da matriz # det(a) # Determinante de uma matriz # solve(a) # Inversa da matriz sqrt(a) # Raiz quadrada dos elementos da matriz ## [,1] [,2] [,3] ## [1,] 1.000000 2.000000 2.645751 ## [2,] 1.414214 2.236068 2.828427 ## [3,] 1.732051 2.449490 3.000000 Funções aceitam os mais diversos tipos de argumentos. Para termos uma ideia de quais utilizarmos e seus respectivos atributos devemos fazer consultas em suas bibliotecas: help(matrix) Além disso, para armazenamento de dados temos os data.frames, tabelas que aceitam dados de tipos distintos: nomes = c(&#39;Carol&#39;, &#39;Alfredo&#39;, &#39;Godoberto&#39;) idade = c(18, 23, 19) peso = c(69, 75, 80) altura = c(1.70, 1.80, 1.85) ICM = peso/altura^2 df = data.frame(nomes, idade, peso, altura, ICM) df ## nomes idade peso altura ICM ## 1 Carol 18 69 1.70 23.87543 ## 2 Alfredo 23 75 1.80 23.14815 ## 3 Godoberto 19 80 1.85 23.37473 "],["medidas-descritivas.html", "Capítulo 3 Medidas Descritivas", " Capítulo 3 Medidas Descritivas Importante: A partir deste capítulo utilizaremos a função kable do pacote knitr para visualização de conjuntos de dados. Na prática isto não é necessário, apenas o realizamos para efeitos de visualização. "],["tipos-de-variáveis.html", "3.1 Tipos de Variáveis", " 3.1 Tipos de Variáveis Antes de analisarmos conjuntos de dados, é necessário termos um conhecimento sobre tipos de variáveis. Para isto, consideremos a seguinte tabela: nome = c(&#39;Djoko&#39;,&#39;Wilson&#39;,&#39;Leon&#39;, &#39;Nilce&#39;) est_civil = c(&#39;Solteiro&#39;,&#39;Casado&#39;, &#39;Casado&#39;, &#39;Casado&#39;) escolaridade = c(&#39;Pós-graduação&#39;, &#39;Ensino médio completo&#39;, &#39;Pós-graduação&#39;, &#39;Superior completo&#39;) n_filhos = c(0, 0, 0, 0) salario = c(4500, 3000, 2000, 5500) idade = c(29, 33, 39, 32) df_youtubers = data.frame(nome, est_civil, escolaridade, n_filhos, salario, idade) kable(df_youtubers, align = &#39;c&#39;, caption = &#39;Dados sobre Youtubers.&#39;) # Melhor visualização dos dados para este PDF Table 3.1: Dados sobre Youtubers. nome est_civil escolaridade n_filhos salario idade Djoko Solteiro Pós-graduação 0 4500 29 Wilson Casado Ensino médio completo 0 3000 33 Leon Casado Pós-graduação 0 2000 39 Nilce Casado Superior completo 0 5500 32 Variáveis como sexo, escolaridade e estado civil apresentam realizações de uma qualidade ou atributo do indivíduo pesquisado, enquanto outras como número de filhos, salário e idade apresentam números como resultados de uma contagem ou mensuração. Chamamos as do primeiro tipo de qualitativas e as do segundo de quantitativas Cada uma das duas ainda pode ser dividida em dois tipos: Variável qualitativa nominal: atributos não apresentam uma ordem lógica; Variável qualitativa ordinal: atributos apresentam uma ordem lógica bem estabelecida; Variável quantitativa discreta: dados de contagem, assumem apenas valores inteiros; Variável quantitativa contínua: dados que podem assumir qualquer tipo de valor. Muitas vezes queremos resumir estes dados, apresentando um ou mais valores que sejam representativos da série toda. Neste contexto entram às medidas de posição e dispersão. "],["medidas-de-posição.html", "3.2 Medidas de Posição", " 3.2 Medidas de Posição Usualmente utilizamos uma das seguintes medidas de posição (ou localização): média, mediana ou moda. Vamos as suas definições: A uma variável atribuiremos a letra \\(X\\) enquanto para seus elementos os valores \\(x_1, \\dots, x_n\\), sendo \\(n\\) o seu total de elementos. Moda: valor mais frequente do conjunto de valores observados. Mediana: valor que ocupa a posição central das observações quando estas estão ordenadas em ordem crescente. Quando o número de observações for par, usa-se como mediana a média aritmética das duas observações centrais. Na tabela 3.1 temos a seguinte mediana para a coluna salário: median(df_youtubers$salario) ## [1] 3750 Matematicamente ordenamos os dados do menor para o maior: \\(2000, 3000, 4500, 5500\\), selecionamos as observações centrais \\(3000\\) e \\(4500\\). Por fim, calculamos a média artimética de ambas, \\(\\frac{3000+4500}{2}\\), para obtermos a mediana. Além disso, podemos calcular a mediana para todas as colunas: # apply: aplica uma função a um conjunto de dados # MARGIN = 2: 1 para aplicar a função a todas as linhas e 2 a todas as colunas # FUN: função a ser aplicada ao conjunto de dados apply(df_youtubers[, c(&#39;n_filhos&#39;,&#39;salario&#39;,&#39;idade&#39;)], MARGIN = 2, FUN = median) ## n_filhos salario idade ## 0.0 3750.0 32.5 Média: soma de todos os elementos do conjunto dividida pela quantidade de elementos do conjunto \\[ \\overline{x} = \\frac{x_1+x_2 + \\dots + x_n}{n} \\] Na tabela 3.1 temos a seguinte média para o salário: mean(df_youtubers$salario) ## [1] 3750 Podemos calcular para todas as colunas que possuam valores numéricos: colMeans(df_youtubers[, c(&#39;idade&#39;, &#39;salario&#39;)]) ## idade salario ## 33.25 3750.00 "],["medidas-de-dispersão.html", "3.3 Medidas de Dispersão", " 3.3 Medidas de Dispersão O resumo de um conjunto de dados por uma única medida representativa de posição esconde toda a informação sobre a variabilidade de um conjunto de observações. Consideremos que cinco alunos realizaram cinco provas, obtendo as seguintes notas: nomes = c(&#39;alunoA&#39;, &#39;alunoB&#39;, &#39;alunoC&#39;, &#39;alunoD&#39;, &#39;alunoE&#39;) notas = matrix(c(3,4,5,6,7, 1,3,5,7,9, 2,5,5,5,8, 3,5,5,5,7, 0,0,5,10,10), nrow = 5, ncol = 5, byrow = T) df_alunos = data.frame(notas, row.names = nomes) colnames(df_alunos) = c(&#39;P1&#39;, &#39;P2&#39;, &#39;P3&#39;, &#39;P4&#39;, &#39;P5&#39;) kable(df_alunos, align = &#39;c&#39;) P1 P2 P3 P4 P5 alunoA 3 4 5 6 7 alunoB 1 3 5 7 9 alunoC 2 5 5 5 8 alunoD 3 5 5 5 7 alunoE 0 0 5 10 10 Temos as seguintes médias para os alunos: # Podemos ver a média de cada coluna utilizando colMeans(df_alunos) rowMeans(df_alunos) ## alunoA alunoB alunoC alunoD alunoE ## 5 5 5 5 5 Cada aluno possui a mesma média de notas, porém, isto não informa nada sobre a diferença na variabilidade das notas. A partir disto, são criadas medidas que sumarizam a variabilidade de um conjunto de observações. Uma primeira ideia é considerar a soma das diferença dos dados em relação a média: \\[ x_1 - \\overline{x} + x_2 - \\overline{x} + \\cdots + x_n - \\overline{x} \\] Porém, podemos mostrar que em qualquer conjunto a soma destes desvios é igual a zero. Uma alternativa é então adicionar o valor absoluto em cada diferença: \\[ |x_1 - \\overline{x}| + |x_2 - \\overline{x}| + \\cdots + |x_n - \\overline{x}| \\] Apesar de possuir uma boa interpretabilidade, tal métrica não possui propriedades matemáticas interessantes. Assim, estatísticos trabalham com a diferença dos dados em relação a média ao quadrado: \\[ (x_1 - \\overline{x})^2 + (x_2 - \\overline{x})^2 + \\cdots + (x_n - \\overline{x})^2 \\] Como muitas vezes queremos comparar conjuntos de dados de diferentes tamanhos, realizamos a divisão desta soma pelo total de elementos em uma amostra e a este número chamamos de variância: \\[ \\text{var}(X) = \\frac{(x_1 - \\overline{x})^2 + (x_2 - \\overline{x})^2 + \\cdots + (x_n - \\overline{x})^2}{n} \\] E a partir disto, definimos desvio padrão como sendo a raiz da variância: \\[ \\text{dp} = \\sqrt{\\text{var}(X)} \\] Realizamos isto pois caso os dados estejam em uma certa unidade de medida, como \\(cm\\) , ao calcularmos a variância passamos a trabalhar com \\(cm^2\\), o que dificulta a interpretabilidade dos resultados. Utilizando o valor na raiz quadrada, voltamos a trabalhar com a unidade de medida utilizada. "],["quantis-empíricos.html", "3.4 Quantis Empíricos", " 3.4 Quantis Empíricos Tanto a média como o desvio padrão podem não ser medidas adequadas para representar um conjunto de dados, uma vez que: São afetados por valores extremos; Apenas os dois valores não dão informação sobre a simetria ou assimetria da distribuição dos dados Vimos que a mediana define uma divisão dos dados em duas metades. Além dela existem medidas chamadas de quantil de ordem p ou p-quantil indicado por \\(q(p)\\) onde \\(p\\) é uma proporção qualquer, \\(0&lt;p&lt;1\\) tal que \\(100\\%\\) das observações sejam menores do que \\(q(p)\\). Abaixo temos alguns dos nomes dos quantis mais utilizados: \\(q(0.25) = q_1:\\) 1° Quartil ou 25° Percentil \\(q(0.50) = q_2:\\) 2° Quartil, Mediana ou 50° Percentil \\(q(0.75) = q_3:\\) 3° Quartil ou 75° Percentil \\(q(0.40) 1:\\) 4° Decil \\(q(0.95):\\) 95° Percentil No R podemos visualizar os quartis da seguinte forma: quantile(df_alunos$P1) ## 0% 25% 50% 75% 100% ## 0 1 2 3 3 Em várias colunas: apply(df_alunos, 2, quantile, seq(0,1,.2)) ## P1 P2 P3 P4 P5 ## 0% 0.0 0.0 5 5.0 7.0 ## 20% 0.8 2.4 5 5.0 7.0 ## 40% 1.6 3.6 5 5.6 7.6 ## 60% 2.4 4.4 5 6.4 8.4 ## 80% 3.0 5.0 5 7.6 9.2 ## 100% 3.0 5.0 5 10.0 10.0 "],["box-plot.html", "3.5 Box Plot", " 3.5 Box Plot A informação contida nos quantis pode ser confusa quando estamos observando vários conjuntos de dados. A partir disto a traduzimos em um diagrama, qual é chamado de box plot: Para construção dessa gráfico definimos por intervalo interquartil o valor: \\[ \\text{IQ}(X) = q_3 - q_1 \\] Desenhamos um retângulo que parte do primeiro quartil até o terceiro, com a mediana sendo representada por uma linha em seu interior. A partir do retângulo desenhamos uma linha até o maior ponto que não exceta o valor \\(q_3+1.5 \\cdot \\text{IQ}(X)\\), chamado de limite superior. De modo análogo fazemos o mesmo procedimento até a parte inferior do retângulo considerando o valor \\(q_1 + 1.5 \\cdot \\text{IQ}(X)\\) chamado de limite interior. As observações que estiverem acima do limite superior ou abaixo do limite superior são chamados de pontos exteriores e representadas por asteriscos. Essas observações podem ser chamaas de outliers ou valores atípicos. Modo simples de como realizar um boxplot pelo R: boxplot(df_alunos, xlab = &quot;Provas&quot;, ylab = &quot;Notas&quot;, main = &quot;Boxplot dos alunos&quot;) O aluno mais atento pode se perguntar: porque alguns dos boxplots não possuem a linha superior e/ou inferior? Isto ocorre quando temos muitos dados em uma mesma categoria, com o primeiro ou terceiro quartil tendo o mesmo valor que o mínimo ou máximo do conjunto de dados: apply(df_alunos, 2, quantile) ## P1 P2 P3 P4 P5 ## 0% 0 0 5 5 7 ## 25% 1 3 5 5 7 ## 50% 2 4 5 6 8 ## 75% 3 5 5 7 9 ## 100% 3 5 5 10 10 O box plot dá uma ideia de posição, dispersão, assimetria dos dados. hist(df_alunos$P4, breaks = seq(5, 10, 0.5)) "],["transformações.html", "3.6 Transformações", " 3.6 Transformações Vários procedimentos estatísticos são baseados na posição que os dados possuem uma distribuição em forma de sino (distribuição normal) ou que a distribuição seja mais ou menos simétrica: # Simula 500 dados de uma distribuição normal dados_normal &lt;- rnorm(n = 10000) # Gráfico de suas frequências hist(dados_normal) Se quisermos utilizar tais procedimentos podemos efetuar transformações nas observações, de modo a se obter uma distribuição mais simétrica e próxima da normal. As transformações mais frequentemente utilizadas são: \\[ x = \\left\\{\\begin{matrix}&amp;\\sqrt{x}\\\\ &amp;\\ln(x) \\\\&amp;\\frac{1}{x}\\end{matrix}\\right. \\] para cada transformação obtemos gráficos apropriados para os dados originais e transformados, de modo a escolhermos o valor mais adequado de \\(p\\). dados_gamma &lt;- rgamma(n = 300, shape = 1) par(mfrow = c(2,2)) # MultiFrame rowwise layout hist(dados_gamma) hist(sqrt(dados_gamma)) hist(1/dados_gamma) hist(log(dados_gamma)) "],["lab-01---conjunto-de-dados-iris.html", "3.7 Lab 01 - Conjunto de dados Iris", " 3.7 Lab 01 - Conjunto de dados Iris O conjunto de dados Iris é um dos mais utilizados quando introduzimos conceitos de ciência de dados. Este pode ser encontrado em UCI Machine Learning Repository. Tal conjunto consiste de 150 amostras de 4 tipos de espécies de flores distintas contendo os atributos: SepalLengthCm SepalWidthCm PetalLengthCm PetalWidthCm Podemos acessá-lo no R sem nenhum carregamento prévio da seguinte forma: # A função head() mostra os cinco primeiros itens de data.frame: head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Há certas boas práticas ao carregar um conjunto de dados, dentre elas temos: Visualização de sua dimensão: # O primeiro valor é a quantidade de linhas do conjunto de dados # e o segundo a sua quantidade de atributos dim(iris) ## [1] 150 5 Visualização do tipo de cada atributo: str(iris) # Structure of an Arbitrary R Object ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... Sumário de seus atributos: summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## Dessa maneira poderemos contatar valores errôneos no conjunto de dados, distribuições de variáveis categóricas e ter um melhor contato com o conjunto de dados. Há ainda diversas maneiras de realizarmos visualizações desse conjunto no R, observemos o boxplot da variável Sepa.Length: boxplot(iris$Sepal.Length) Observamos que não há presença de outliers, além disso, como a parte debaixo do retângulo separado pela linha que representa a mediana é menor, isto indica que a distribuição dos dados é ligeiramente assimétrica, o qual é confirmado pelo histograma: hist(iris$Sepal.Length) ggplot(data = iris, aes(x = Sepal.Length, fill = ..count..)) + geom_histogram(binwidth = 0.25, boundary = 0) + scale_x_continuous(breaks = seq(1, 10, by = 0.25)) "],["lab-02---xadrez-brasil.html", "3.8 Lab 02 - Xadrez Brasil", " 3.8 Lab 02 - Xadrez Brasil Em 2022 houve uma polêmica no universo de xadrez entre o atual campeão mundial de xadrez Magnus Carlsen e o jovem grande mestre Hanns Niemann, qual possui um histórico de trapaças e foi acusado de repetir estes atos no torneio. Magnus chegou a abandonar o torneio motivado por acreditar que seu oponente utilizava de engines em sua partida. Baseado nisso vários estatísticos se debrulharam entre as partidas de Niemann com o objetivo de encontrar evidências de sua rápida ascensão no xadrez, qual bateu recordes como grande mestre mais rápido da história. Uma destas analises foi realizada pelo canal brasileiro de youtube Xadrez Brasil, e nela podemos observar como medidas de posição e dispersão podem ser utilizadas para fortalecer ou não a hipótese de que Niemann estava trapaçeando. https://www.youtube.com/watch?v=60QPEGsOCyw "],["introdução-à-pacotes-do-r-e-ao-tidyverse.html", "Capítulo 4 Introdução à pacotes do R e ao Tidyverse", " Capítulo 4 Introdução à pacotes do R e ao Tidyverse Pacotes são conjuntos de códigos criados para a linguagem R de forma que as mais diversas funcionalidades sejam simplificadas e padronizadas. Para trabalharmos com análise de dados utilizaremos pacotes do tidyverse, uma coleção de pacotes utilizados para manipulação de dados que compartilham uma filosofia em comum e são projetados para serem trabalhados em conjunto. Muitos deles não são nativos da linguagem e devem ser instalados utilizando a função install.packages. Neste capítulo trabalharemos com: Dplyr: Manipulação de conjunto de dados Tidyr: Modelagem no formato de conjuntos de dados GGPlot2: Visualização de conjuntos de dados Stringr: Manipulação de texto Forcats: Manipulação de fatores Inicialmente devemos realizarmos a intalação dos pacotes: install.packages(&#39;dplyr&#39;) install.packages(&#39;tidyr&#39;) install.packages(&#39;ggplot2&#39;) install.packages(&#39;stringr&#39;) install.packages(&#39;forcats&#39;) # install.packages(&#39;tidyverse&#39;) Instala todos os pacotes do tidyverse de uma vez e em seguida podemos carregar os pacotes no R: library(dplyr) # Manipulação de dados library(tidyr) # Modificação no formato de conjuntos de dados library(ggplot2) # Visualização de gráficos library(stringr) library(forcats) library(readr) # Biblioteca para leitura de dados Também podemos carregar vários em uma linha de código utilizando a biblioteca easypackages: install.packages(&#39;easypackages&#39;) # Instalar a biblioteca library(easypackages) # Carrega o pacote libraries(&#39;dplyr&#39;, &#39;tidyr&#39;, &#39;ggplot2&#39;, &#39;stringr&#39;, &#39;forcats&#39;, &#39;readr&#39;) Trabalharemos especialmente com Data Munging, processo de preparar conjuntos de dados para relatórios e análises. Esta parte incorpora todas as etapas anteriores à análise, incluindo estruturação de dados, limpeza, enriquecimento e validação. "],["dados-utilizados.html", "4.1 Dados utilizados", " 4.1 Dados utilizados Antes de utilizarmos as bibliotecas comentemos um pouco sobre os conjuntos de dados a serem utilizados nos processos. 4.1.1 Motor Trend Car Road Test (mtcars) Conjunto de dados nativo do R extraído da revista Motor Trend US de 1974. Possui diversos atributos de veículos dessa época e não precisa ser carregado de forma externa, estes já são salvos na variável mtcars. 4.1.2 Pokémons Dataset Presente em animações, jogos, filmes, séries e em toda a cultura nerd, Pokémon é uma série contendo os nossos monstrinhos favoritos! Utilizaremos aqui o conjunto com uma lista com todos os pokémons até então presente nos jogos, com seus nomes, tipos, status, classificação em lendário dentre outros atributos. Podemos encontrar o conjunto no site Kaggle. pokemon_stats &lt;- read_csv(&quot;G:/Meu Drive/Dados/pokemon_stats.csv&quot;) 4.1.3 Fifa 2022 Player Dataset FIFA é uma das principais franquias, se não a principal, de jogos de futebol, onde se concentra a maioria dos times e jogadores do esporte. Nos jogos cada jogador possui diferentes atributos e características que influenciam umas nas outras. Aqui consideraremos o conjunto de dados destes jogadores no jogo FIFA 22. As informações estão divididas em dois conjuntos e serão destaque quando trabalharmos sobre união e intersecção de conjuntos de dados. fifa_basic &lt;- read_csv(&quot;G:/Meu Drive/Dados/fifa_basic_info.csv&quot;) fifa_detailed &lt;- read_csv(&quot;G:/Meu Drive/Dados/fifa_detailed_info.csv&quot;) "],["introdução-a-fatores.html", "4.2 Introdução a fatores", " 4.2 Introdução a fatores Fatores são objetos para armazenamento de dados categóricos no R. A grande maioria dos algoritmos de aprendizado de máquina não trabalha com textos, mas sim com valores numéricos - transformar dados que estão armazenados como texto em fatores é um fator primordial para que os algoritmos os interpretem como dados categóricos. No conjunto de dados sobre pokémons, o Tipo de cada pokémon é armazenado por uma string (texto): str(pokemon_stats[&#39;Type_1&#39;]) ## tibble [721 × 1] (S3: tbl_df/tbl/data.frame) ## $ Type_1: chr [1:721] &quot;Grass&quot; &quot;Grass&quot; &quot;Grass&quot; &quot;Fire&quot; ... Se quisermos trabalhar de forma a utilizarmos essa coluna em algoritmos, ou até mesmo para certos pacotes que trabalham com dados categóricos, como ggplot2 para criação de certos gráficos, o ideal é realizar a transformação para fator: pokemon_stats$Type_1 = as.factor(pokemon_stats$Type_1) class(pokemon_stats$Type_1) # Classe dessa coluna passa a ser do tipo fator ## [1] &quot;factor&quot; Podemos transformar várias colunas em fatores utilizando a função apply: colunas = c(&#39;Type_1&#39;, &#39;Type_2&#39;) pokemon_stats[colunas] = lapply(pokemon_stats[colunas], factor) A diferença entre as funções da família apply é sútil. Estas variam com o tipo de dado esperado como entrada das funções e seu resultado, recomendo o post de Fernando Gama no medium sobre o assunto. "],["trabalhando-com-datas.html", "4.3 Trabalhando com Datas", " 4.3 Trabalhando com Datas https://www.r-bloggers.com/2013/08/date-formats-in-r/ as.POSIXct(fifa_detailed$DOB, format = &quot;%h %d, %Y&quot;) "],["dplyr-tidyr.html", "Capítulo 5 Dplyr &amp; Tidyr", " Capítulo 5 Dplyr &amp; Tidyr Dplyr e Tidyr são pacotes que se complementam na manipulação de dados. O primeiro foca na realização de manipulação enquanto o segundo na modificação de seu formato. Aqui utilizaremos como referência a folha de referência de ambas as bibliotecas. Além disso recomendo a consulta do site Rdocumentation para visualização de todas as funções dos pacotes. Vamos então aos principais recursos das bibliotecas. "],["extração-de-observações-linhas.html", "5.1 Extração de Observações (Linhas)", " 5.1 Extração de Observações (Linhas) 5.1.1 filter Muitas vezes queremos selecionar algumas linhas que satisfaçam um critério lógico. Consideremos o conjunto mtcars, o número de cilindros de cada carro varia entre 4, 6 e 8 Cyl Freq 4 11 6 7 8 14 Caso estejamos interessados em selecionar apenas os carros com 4 cilindros primeiro utilizamos o operador lógico == para verificarmos a igualdade de um vetor em relação a um valor. Caso na n-ésima linha a condição seja satisfeita, a n-ésima posição do vetor será retornada como TRUE. Caso contrário teremos um FALSE nesta posição. condic_logica &lt;- mtcars$cyl == 4 condic_logica ## [1] FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE TRUE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE FALSE FALSE FALSE ## [25] FALSE TRUE TRUE TRUE FALSE FALSE FALSE TRUE Após isto podemos então utilizar a função filter. O primeiro parâmetro são os dados a serem filtrados enquanto o segundo é a condição lógica utilizada. filter(.data = mtcars, condic_logica) Podemos aplicar mais de uma condição lógica de duas formas. A primeira é passarmos múltiplos argumentos através da função filter. A segunda é utilizarmos os operadores lógicos “e” (&amp;) e “ou” (|). &amp;: Ambas as condições precisam ser satisfeitas; |: Apenas uma das condições precisa ser satisfeita. Caso queiramos selecionar os carros com 4 cilindros e mais do que 100 cavalos de potência: filter(.data = mtcars, mtcars$cyl == 4, mtcars$hp &gt; 100) # Também podemos realizar #filter(.data = mtcars, mtcars$cyl == 4 &amp; mtcars$hp &gt; 100) Caso queiramos selecionar os carros com 4 cilindros ou mais do que 100 cavalos de potência: filter(.data = mtcars, mtcars$cyl == 4 | mtcars$hp &gt; 100) Há uma diferença clara entre os operadores. No primeiro queremos que ambas as condições sejam satisfeitas enquanto no segundo, queremos qualquer linha que tenha uma delas satisfeita. 5.1.2 distinct Remove linhas duplicadas do conjunto de dados. alunos = data.frame(Alunos = c(&quot;Gabriel&quot;, &quot;Gabriel&quot;, &quot;Renato&quot;)) distinct(alunos) ## Alunos ## 1 Gabriel ## 2 Renato 5.1.3 O Operador Pipe A ideia do operador pipe, %&gt;% é bem simples, usar o valor resultante da expressão do lado esquerdo como primeiro argumento da função do lado direito. mtcars %&gt;% filter((mtcars$cyl == 4) &amp; (mtcars$hp &gt; 100)) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.9 1 1 5 2 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.6 1 1 4 2 Também podemos passar a expressão do lado esquerdo como um certo parâmetro de u margumento da função, evidenciando por . no parâmetro que queremos. Isto ajuda a tornar o código mais legível quando analisado por outras pessoas (ou nós mesmos em outros dias). A partir daqui sempre utilizaremos o operador pipe! 5.1.4 sample_frac Seleciona uma fração das linhas do conjunto de dados aleatoriamente mtcars %&gt;% sample_frac(0.7, replace = FALSE) # Se replace = TRUE então uma mesma linha pode ser selecionada múltiplas vezes 5.1.5 slice Seleciona linhas pela posição # Vamos selecionar as linhas 10, 12, 14, 16, 18 e 20: mtcars %&gt;% slice(seq(10, 20, 2)) "],["extração-de-variáveis-colunas.html", "5.2 Extração de Variáveis (Colunas)", " 5.2 Extração de Variáveis (Colunas) A seleção de colunas é feita sxclusivamente com a função select. Nela passamos todas as colunas que queremos selecionar em um conjunto de dados: mtcars %&gt;% select(mpg, cyl, hp) Leitores mais atentos podem estar se perguntando a vantagem de se utilizar select comparado aos métodos nativos da própria linguagem R. A mais óbvia é por sua legibilidade no conjunto de dados, mas esta não é a única. Podemos utilizar de funções auxiliares para seleção de colunas. Isto pode não ser necessário quando trabalhamos com conjunto de dados pequenos, mas imagine trabalhando bom dados que possuem mais do que 500 colunas, o que é bem comum quando trabalhamos com Big Data. Vamos a alguns exemplos: # Seleciona as cinco primeiras colunas mtcars %&gt;% select(1:5) # Seleciona colunas cujo nome contém alguma string: mtcars %&gt;% select(contains(&quot;a&quot;)) # Seleciona todas as colunas entre hp e gear: mtcars %&gt;% select(hp:gear) # Seleciona todas as colunas, menos hp mtcars %&gt;% select(-hp) "],["resumir-dados.html", "5.3 Resumir dados", " 5.3 Resumir dados Resumo de dados consiste na utilização de métricas como média, mediana ou variância para termos melhor informações dos nossos dados. Dentre estas podemos utilizar: min: menor valor de um vetor; max: maior valor de um vetor; mean: média de um vetor; median: mediana de um vetor; var: variância de um vetor; sd: desvio padrão de um vetor. Podemos aplicar estas funções em múltiplas colunas ou aplicarmos várias em colunas distintas. Vamos aos exemplos. 5.3.1 summarise Resume os dados em uma única linha de valores pokemon_stats %&gt;% summarise(tot_mean = mean(Total), tot_std = sd(Total)) ## # A tibble: 1 × 2 ## tot_mean tot_std ## &lt;dbl&gt; &lt;dbl&gt; ## 1 418. 110. É melhor utilizado quando trabalhamos com a função group_by. 5.3.2 summarise_each Aplica a função em cada coluna dos dados: pokemon_stats %&gt;% select(Total:Speed) %&gt;% # Vamos selecionar apenas algumas colunas de atributos numéricos dos dados summarise_each(mean) ## Warning: `summarise_each_()` was deprecated in dplyr 0.7.0. ## Please use `across()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## # A tibble: 1 × 7 ## Total HP Attack Defense Sp_Atk Sp_Def Speed ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 418. 68.4 75.0 70.8 68.7 69.3 65.7 5.3.3 count Conta o número de linhas com cada valor único de uma variável count(mtcars, cyl) # Similar ao table() ## cyl n ## 1 4 11 ## 2 6 7 ## 3 8 14 "],["criação-de-novas-variáveis.html", "5.4 Criação de Novas Variáveis", " 5.4 Criação de Novas Variáveis Criação de novas colunas nos conjunstos de dados. 5.4.1 mutate Calcula e acrescenta uma ou mais colunas # Vamos criar uma coluna retornando TRUE se o pokémon tiver Speed &gt; 100 # e Attack ou Sp_Atk maior que 100: pokemon_stats %&gt;% mutate(Atacante = ifelse((Attack &gt; 100 &amp; Speed &gt; 100) | (Sp_Atk &gt; 100 &amp; Speed &gt; 100), TRUE, FALSE)) 5.4.2 transmute Calcula uma ou mais novas colunas, removendo as originais. Útil quando queremos transformar todas as colunas de um conjunto de dados, removendo as colunas originais. Vamos supor que só estamos interessados apenas no nome, tipo de corpo e IMC de cada pokémon: pokemon_stats %&gt;% transmute(Nome = Name, Body_Style = Body_Style, IMC = round(Weight_kg / Height_m^2,2)) "],["combinar-conjuntos-de-dados.html", "5.5 Combinar Conjuntos de Dados", " 5.5 Combinar Conjuntos de Dados Muitas vezes queremos trabalhar com dados que estão em arquivos distintos. Isto é comum em bancos de dados, onde várias informações são guardadas em diferentes arquivos. Nos exemplos abaixo iremos trabalhar com os dados do conjunto FIFA, que apresentam a variável ID como indicação de jogadores. Quem já trabalhou com conjuntos no Ensino Médio ou até mesmo teve um primeiro contato com a linguagem SQL já ouviu falar sobre tipos de join. Estes são formas de unir tabelas a partir de uma certa ordem e se dividem em quatro tipos: left, right, inner e full: Tipos de Join. A diferença entre eles é qual conjunto de dados será utilizado como referência para a união de ambos. 5.5.1 left_join A primeira tabela é utilizada como referência na hora de combinar ambos os conjuntos. Assim todas as linhas do primeiro parâmetro serão combinadas com a utilizada como segundo: # No parâmetro &quot;by&quot; passamos por a variável que queremos realizar o agrupamento left_join(fifa_detailed, fifa_basic, by = &#39;ID&#39;) A lógica do right_join é análoga, sendo o conjunto de dados do segundo parâmetro como fixo: # No parâmetro &quot;by&quot; passamos por a variável que queremos realizar o agrupamento right_join(fifa_detailed, fifa_basic, by = &#39;ID&#39;) Ambos os resultados não são iguais: O primeiro código retorna um conjunto de dados com 14705 observações enquanto o segundo com 19825 observações! 5.5.2 inner_join Une ambos os conjuntos, porém apenas linhas presentes em ambos são consideradas: inner_join(fifa_detailed, fifa_basic, by = &#39;ID&#39;) 5.5.3 full_join Une os dados mantendo todos os valores e todas as linhas. Valores faltantes são atribuídos a NA fifa_merged &lt;- full_join(inner_join(fifa_detailed, fifa_basic, by = &#39;ID&#39;), fifa_basic, by = &#39;ID&#39;) "],["agrupar-dados-group_by.html", "5.6 Agrupar Dados (group_by)", " 5.6 Agrupar Dados (group_by) Agrupa variáveis de acordo com um ou mais categoria. A função em si não modifica o conjunto, mas as próximas serão modificadas pela forma que os dados estão agrupados. Vamos calcular a média de status de pokémons pelos seus primeiros tipos: pokemon_stats %&gt;% group_by(Type_1) %&gt;% # Agrupa por Tipo summarise(Tot_mean = mean(Total)) "],["remodelando-dados.html", "5.7 Remodelando Dados", " 5.7 Remodelando Dados Mudar o formato e configuração dos dados permite separar variáveis que estão em uma coluna em mais de uma ou unir várias colunas em uma. Além disso podemos mudar o nome de colunas ou até mesmo ordenar seus valores de forma crescente. A biblioteca tidyr é perfeita para para isto, imagine-se trabalhando com a variável mês e dia em um conjunto de dados. Em vários algoritmos é interessante considerarmos o mês e o dia como atributos separados, assim cada um é alocado a uma coluna do conjunto de dados para que possamos realizar o ajuste dos algoritmos. 5.7.1 arrange Ordena linhas pelos valores de uma coluna (menor para o maior). Vamos utilizar como exemplo a ordenação da média dos atributos do pokémon por tipo: pokemon_stats %&gt;% group_by(Type_1) %&gt;% # Agrupa por Tipo summarise(Tot_mean = mean(Total)) %&gt;% arrange(Tot_mean) Caso estejamos interessados em ordenar os valores do maior para o menor utilizamos a função desc para a coluna dentro da função arange: pokemon_stats %&gt;% group_by(Type_1) %&gt;% # Agrupa por Tipo summarise(Tot_mean = mean(Total)) %&gt;% arrange(desc(Tot_mean)) 5.7.2 rename Renomeia colunas do conjunto de dados pokemon_stats %&gt;% rename(Nome = Name, Tipo_I = Type_1, Tipo_2 = Type_2) 5.7.3 separate Para as próximas funções utilizaremos os dados de fifa_deitaled, em particular a coluna Work Rate. A função separate separa uma coluna em uma ou mais linhas fifa_separate &lt;- fifa_detailed %&gt;% separate(col = `Work rate`, into = c(&quot;Work1&quot;, &quot;Work2&quot;), sep = &quot;/&quot;) 5.7.4 unite Une várias colunas em uma. Vamos considerar a coluna Work1 e Work2 que separamos anteriormente. Poderíamos retorná-las ao estado anterior da seguinte forma: fifa_separate %&gt;% unite(col = &quot;Work rate&quot;, c(Work1, Work2), sep = &quot;-&quot;) %&gt;% select(&quot;Work rate&quot;) "],["ggplot2.html", "Capítulo 6 GGPlot2", " Capítulo 6 GGPlot2 Pacote para criação de gráficos baseado no livro The Grammar of Graphics, que destrincha todas as componentes de um gráfico estatístico em partes individuais. Grammar of Graphics. Vamos aos componentes eu a biblioteca se baseia: Data: Dados que serão utilizados para visualização; Aesthetic (Estética): Argumentos para realizar a visualização dos dados; x, y: variável em cada eixo; colour: variável para colorir objetos geométricos ; fill: variável para colorir dentro de objetos geométricos; group: forma em que os dados podem ser agrupados; shape: formato dos pontos; linetype: tipo de linha a ser utilizado; size: escala utilizada para pontos, retângulos; alpha: transparência dos objetos geométricos. Objetos geométricos: determinam o tipo de gráfico; Facets: para múltiplos gráficos diferindo por grupos; Statistics: Informações estatísticas como médias, quantidade de ocorrências; Cordenadas: Tipo de coordenada, pode ser cartesiana, polar e de projeção; Temas: Fonte, cores, tamanho, formato dos objetos do gráfico. Observemos então como ggplot2 utiliza desta teoria na prática. Caso o leitor queira se aprofundar nos conceitos trabalhados aqui ou busque por algum gráfico em específico recomendamos R Graphics Cookbook, 2nd edition. Inicialmente devemos carregar os nossos dados, podendo ou não já atribuirmos uma estética a ele: # A variável Type_1 será considerada para o eixo x, enquanto a y ainda não foi definida: ggplot(data = mtcars, aes(x = wt, y = mpg)) # ggplot(data = mtcars) também é uma opção válida! # Porém aqui os eixos não serão criados. "],["gráficos-de-barras.html", "6.1 Gráficos de Barras", " 6.1 Gráficos de Barras "],["gráficos-de-linha.html", "6.2 Gráficos de Linha", " 6.2 Gráficos de Linha "],["gráficos-de-dispersão.html", "6.3 Gráficos de Dispersão", " 6.3 Gráficos de Dispersão "],["anotações.html", "6.4 Anotações", " 6.4 Anotações "],["eixos.html", "6.5 Eixos", " 6.5 Eixos "],["controlando-a-aparência-do-gráfico.html", "6.6 Controlando a Aparência do Gráfico", " 6.6 Controlando a Aparência do Gráfico "],["facets.html", "6.7 Facets", " 6.7 Facets "],["projeto-01---machine-learning-from-disaster.html", "6.8 Projeto 01 - Machine Learning from Disaster", " 6.8 Projeto 01 - Machine Learning from Disaster Vamos utilizar o que aprendemos até então para trabalharmos com o conjunto de dados do Titanic: "],["stringr.html", "Capítulo 7 Stringr", " Capítulo 7 Stringr "],["forcats.html", "Capítulo 8 Forcats", " Capítulo 8 Forcats "],["web-scraping.html", "Capítulo 9 Web Scraping", " Capítulo 9 Web Scraping "],["introdução-à-probabilidade.html", "Capítulo 10 Introdução à Probabilidade", " Capítulo 10 Introdução à Probabilidade "],["tipos-de-distribuições-discretas.html", "Capítulo 11 Tipos de Distribuições Discretas", " Capítulo 11 Tipos de Distribuições Discretas Para atender a situações mais práticas, é necessário expandir os conceitos relacionados a probabilidade de forma que tenhamos modelos probabilísticos que representem todos os tipos de variáveis. Neste capítulo trabalharemos com variáveis quantativas discretas. Exemplo (Bussab): Chamamos de variável aleatória discreta uma função \\(X\\) definida no espaço amostral \\(\\Omega\\) que assume valores em um conjunto de números finito. Neste contexto vimos como associar a cada valor \\(x_i\\) da variável aleatória \\(X\\) a sua probabilidade de ocorrência. Matematicamente, escrevemos Além disso, chamamos de função de probabilidade da variável aleatória discreta \\(X\\) a função que a cada valor de \\(x_i\\) associa a sua probabilidade de ocorrência \\[ p(x_i) = P(X=x_i) = p_i, i =1, 2, \\dots \\] "],["valor-médio-de-uma-variável-aleatória.html", "11.1 Valor Médio de uma Variável Aleatória", " 11.1 Valor Médio de uma Variável Aleatória Dada uma variável aleatórai \\(X\\) discreta, assumindo os valores $x_1,\\dots, x_n$, chamamos de valor médio ou esperança de \\(X\\) o valor \\[ E[X] = \\sum_{i=1}^n x_i P(X=x_i) = \\sum_{i=1}^n x_i p_i. \\] Chamamos de variância da variável aleatória \\(X\\) o valor \\[ \\text{var}[X] = \\sum_{i=1}^n [x_i - E[X]]^2 p_i \\] "],["tipos-de-distribuições-contínuas.html", "Capítulo 12 Tipos de Distribuições Contínuas", " Capítulo 12 Tipos de Distribuições Contínuas "],["introdução-à-inferência.html", "Capítulo 13 Introdução à Inferência", " Capítulo 13 Introdução à Inferência "],["introdução-ao-machine-learning.html", "Capítulo 14 Introdução ao Machine Learning", " Capítulo 14 Introdução ao Machine Learning "],["regressão-linear.html", "Capítulo 15 Regressão Linear", " Capítulo 15 Regressão Linear Em problemas de aprendizagem supervisionada regressão linear é o algoritmo mais simples que podemos utilizar. A muito tempo é tema de diversos livros e, apesar de parecer descartável com algoritmos mais modernos, ainda é uma ferramente muito útil para diversos processos estatísticos. "],["regressão-linear-simples.html", "15.1 Regressão Linear Simples", " 15.1 Regressão Linear Simples Maneira mais direta de prever uma resposta \\(Y\\) através de uma variável preditora \\(X\\). Assume que exista uma relação linear entre \\(X\\) e \\(Y\\), qual pode ser escrita da seguinte forma \\[ Y \\approx \\beta_0 + \\beta_1 X. \\] Onde \\(\\approx\\) significa que \\(Y\\) é aproximadamente uma soma linear de $X$. No conjunto mtcars \\(Y\\) pode ser a variável mpg enquanto \\(X\\) a variável hp. \\[ \\text{mpg} \\approx \\beta_0 + \\beta_1 \\text{hp}. \\] Nestas equações os parâmetros \\(\\beta_0\\) e \\(\\beta_1\\) são duas constantes desconhecidas que representam o intercepto e o coeficiente angular de uma curva. Chamamos estes de coeficientes ou parâmetros do modelo de regressão linear. Uma vez que tenhamos utilizados os dados de treino para estimar os parâmetros, os denotamos com um chapéu em cima, indicando que são os parâmetros estimados através dos dados. Podemos então prever novos dados por meio da equação: \\[ \\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x, \\] onde \\(\\hat{y}\\) é a predição realizada pelo algoritmo para a variável \\(X=x\\). "],["estimando-os-coeficientes.html", "15.2 Estimando os Coeficientes", " 15.2 Estimando os Coeficientes Na prática os parâmetros do modelo são desconhecidos. Para estíma-los vamos considerar que temos um conjunto de dados com \\(n\\) linhas: \\[ (x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n) \\] Cada um representando um valor para \\(X\\) e $Y$. Temos como objetivo estimar \\(\\beta_0\\) e \\(\\beta_1\\) de modo que o modelo linear realize boas previsões, isto é \\[ y_i \\approx \\hat{\\beta_0} + \\hat{\\beta_1}x_i, i=1,\\dots, n \\] Isto significa que queremos encontrar uma reta que esteja o mais próximo possível de todos os pontos. Tanto visualmente, tanto computacionalmente, a linguagem R já possui boas ferramentas para isto. Tanto para visualização: ggplot(mtcars, aes(x = hp, y = mpg)) + geom_point() + geom_smooth(formula = y ~ x,method = &#39;lm&#39;, se = FALSE) + labs(title = &#39;Regressão linear no conjunto mtcars&#39;) Tanto para criarmos um objeto que represente o modelo de regressão com a função lm: mtcars_lm &lt;- lm(mpg ~ hp, data = mtcars) mtcars_lm ## ## Call: ## lm(formula = mpg ~ hp, data = mtcars) ## ## Coefficients: ## (Intercept) hp ## 30.09886 -0.06823 Existem diversas maneiras de calcular o quanto uma reta está próxima de um conjunto de pontos. Aqui focaremos na minimização dos mínimos quadrados. Seja a previsão de \\(Y\\) para o i-ésimo valor de $X$. O erro cometido entre o valor real de \\(y_i\\) e sua previsão é \\(e_i=y_i-\\hat{y_i}\\), qual chamamos de i-ésimo resíduo. Definimos como soma dos quadrados dos resíduos o valor \\[ \\text{RSS} = e_1^2+e_2^2+\\dots + e_n, \\] ou equivalentemente \\[ \\text{RSS} = (y_1- \\beta_0-\\hat{\\beta_1}x_1)^2 + (y_2- \\beta_0-\\hat{\\beta_1}x_2)^2 +\\cdots + (y_n- \\beta_0-\\hat{\\beta_1}x_n)^2 \\] O método consiste na escolha de \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\) que minimizam esta soma. Com conceitos do cálculo, podemos demonstrar que \\[ \\hat{\\beta_1} = \\dfrac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i- \\overline{y})}{\\sum_{i=1}^n (x_i-\\overline{x})^2}, \\quad \\hat{\\beta_0}=\\overline{y} - \\hat{\\beta_1}\\overline{x}. \\] são os valores de \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\) que minimizam a soma dos quadrados dos resíduos. Elaboremos uma função que realize o cálculo desses coeficientes: linear_regression &lt;- function(X, Y){ numerador = sum((X - mean(X)) * (Y - mean(Y))) denominador = sum((X - mean(X))**2) beta_1 = numerador/denominador beta_0 = mean(Y) - beta_1 * mean(X) return(data.frame(&#39;beta_0&#39; = beta_0, &#39;beta_1&#39; = beta_1)) } linear_regression(X = mtcars$hp, Y = mtcars$mpg) ## beta_0 beta_1 ## 1 30.09886 -0.06822828 "],["acurácia-da-estimativa-dos-coeficientes.html", "15.3 Acurácia da Estimativa dos Coeficientes", " 15.3 Acurácia da Estimativa dos Coeficientes "],["regressão-linear-múltipla.html", "15.4 Regressão Linear Múltipla", " 15.4 Regressão Linear Múltipla "],["questões-importantes-sobre-o-modelo-linear.html", "15.5 Questões Importantes Sobre o Modelo Linear", " 15.5 Questões Importantes Sobre o Modelo Linear library(ggplot2) library(tidyr) library(dplyr) "],["projeto-01---machine-learning-from-disaster-1.html", "Capítulo 16 Projeto 01 - Machine Learning from Disaster", " Capítulo 16 Projeto 01 - Machine Learning from Disaster Todo mundo já assistiu, ou pelo menos ouviu falar, sobre o desastre do navio Titanic. Incrivelmente este caso também pode ser estudado utilizando aprendizado de máquina! Na verdade este é um dos primeiros desafios que trabalhamos quando estudamos nossos primeiros algoritmos. O conjunto de dados e suas informações pode ser encontrado no site Kaggle, um site que hospeda diversos conjuntos de dados e competições de machine learning. Na aula aprenderemos como baixamos e analisamos as observaçõs contidas nesse conjunto de dados, qual pode ser visualizado na tabela abaixo: library(readr) titanic_train &lt;- read_csv(&quot;G:/Meu Drive/Dados/titanic_train.csv&quot;) O objetivo do trabalho é prever se um passageiro sobreviveu ou não ao naufrágio do Titanic. Para começarmos trabalharemos com a função str para observarmos os tipos de variáveis presentes na tabela: str(titanic_train) ## spec_tbl_df [891 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ PassengerId: num [1:891] 1 2 3 4 5 6 7 8 9 10 ... ## $ Survived : num [1:891] 0 1 1 1 0 0 0 0 1 1 ... ## $ Pclass : num [1:891] 3 1 3 1 3 3 1 3 3 2 ... ## $ Name : chr [1:891] &quot;Braund, Mr. Owen Harris&quot; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot; &quot;Heikkinen, Miss. Laina&quot; &quot;Futrelle, Mrs. Jacques Heath (Lily May Peel)&quot; ... ## $ Sex : chr [1:891] &quot;male&quot; &quot;female&quot; &quot;female&quot; &quot;female&quot; ... ## $ Age : num [1:891] 22 38 26 35 35 NA 54 2 27 14 ... ## $ SibSp : num [1:891] 1 1 0 1 0 0 0 3 0 1 ... ## $ Parch : num [1:891] 0 0 0 0 0 0 0 1 2 0 ... ## $ Ticket : chr [1:891] &quot;A/5 21171&quot; &quot;PC 17599&quot; &quot;STON/O2. 3101282&quot; &quot;113803&quot; ... ## $ Fare : num [1:891] 7.25 71.28 7.92 53.1 8.05 ... ## $ Cabin : chr [1:891] NA &quot;C85&quot; NA &quot;C123&quot; ... ## $ Embarked : chr [1:891] &quot;S&quot; &quot;C&quot; &quot;S&quot; &quot;S&quot; ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. PassengerId = col_double(), ## .. Survived = col_double(), ## .. Pclass = col_double(), ## .. Name = col_character(), ## .. Sex = col_character(), ## .. Age = col_double(), ## .. SibSp = col_double(), ## .. Parch = col_double(), ## .. Ticket = col_character(), ## .. Fare = col_double(), ## .. Cabin = col_character(), ## .. Embarked = col_character() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; Temos dados do tipo texto e numéricos. Inicialmente excluíremos do conjunto de dados os nomes, por representarem atributos que não são relevantes para previsões: titanic_train &lt;- titanic_train %&gt;% select(-c(PassengerId, Name, Ticket, Cabin)) Além disto, vamos transformar os dados categóricos em fatores: cols &lt;- c(&#39;Survived&#39;, &#39;Pclass&#39;, &#39;Embarked&#39;) titanic_train[cols] = lapply(titanic_train[cols], factor) Observemos agora se nosso conjunto de dados possui valores faltantes: summary(titanic_train) ## Survived Pclass Sex Age SibSp ## 0:549 1:216 Length:891 Min. : 0.42 Min. :0.000 ## 1:342 2:184 Class :character 1st Qu.:20.12 1st Qu.:0.000 ## 3:491 Mode :character Median :28.00 Median :0.000 ## Mean :29.70 Mean :0.523 ## 3rd Qu.:38.00 3rd Qu.:1.000 ## Max. :80.00 Max. :8.000 ## NA&#39;s :177 ## Parch Fare Embarked ## Min. :0.0000 Min. : 0.00 C :168 ## 1st Qu.:0.0000 1st Qu.: 7.91 Q : 77 ## Median :0.0000 Median : 14.45 S :644 ## Mean :0.3816 Mean : 32.20 NA&#39;s: 2 ## 3rd Qu.:0.0000 3rd Qu.: 31.00 ## Max. :6.0000 Max. :512.33 ## A coluna de idade apresenta 177 valores faltantes, ou seja aproximadamente \\(20\\%\\) dos dados não estão com o atributo idade. Existem diversas formas, com as mais diversas teorias para lidarmos com estes valores, aqui vão algumas: Se a quantidade de valores faltantes é muito grande, retiramos a coluna do conjunto de dados; Se a quantidade é muito pequena, retiramos a linha do conjunto de dados; Completar estes valores com a média da coluna para valores numéricos ou com a moda para valores categóricos. O que é uma quantidade muito grande ou pequena de valores faltantes? Isto depende do problema! Temos 2 valores faltantes na coluna Embarked que, ao serem retirados, provavelmente não causem nenhum impacto no modelo final. Aqui é importante utilizarmos o nosso bom senso, além de testarmos as mais diversas possibilidades, uma vez que alguns modelos podem ser fortemente por outiliers, por exemplo. Vamos então excluir os valores faltantes de Embarked e completar a coluna Age com a média da coluna: titanic_train &lt;- titanic_train %&gt;% drop_na(Embarked) E completar os valores da idade com a média: titanic_train$Age &lt;- titanic_train$Age %&gt;% replace_na(mean(titanic_train$Age, na.rm = T)) Dessa realizamos um preparo inicial para o conjunto de dados! A criação do algoritmo de regressão logística é simples: titanic_reg &lt;- glm(Survived ~ ., data = titanic_train, family = binomial(link = &#39;logit&#39;)) Para carregarmos o conjunto de teste e então realizarmos previsões: titanic_test &lt;- read_csv(&quot;G:/Meu Drive/Dados/titanic_test.csv&quot;) Lembrando que as colunas do conjunto de teste, qual queremos realizar as previsões deve estar de acordo com o de treinamento! titanic_test &lt;- titanic_test %&gt;% select(-c(PassengerId, Name, Ticket, Cabin)) cols &lt;- c(&#39;Pclass&#39;, &#39;Embarked&#39;) titanic_test[cols] = lapply(titanic_test[cols], factor) titanic_test$Age &lt;- titanic_test$Age %&gt;% replace_na(mean(titanic_test$Age, na.rm = T)) # A coluna Fare apresenta um valor NA e este será atribuído a média: titanic_test$Fare &lt;- titanic_test$Fare %&gt;% replace_na(mean(titanic_test$Fare, na.rm = T)) Para porfim realizarmos as previsões: probabilidades &lt;- predict(titanic_reg, titanic_test, type = &quot;response&quot;) classes_prev &lt;- ifelse(probabilidades &gt; 0.5, 1, 0) Por fim, criemos o conjunto de dados para ser enviado ao Kaggle: kaggle_titanic &lt;- data.frame(PassengerId = 892:1309, Survived = classes_prev) Por fim, salvemos o nosso data.frame em um arquivo csv: write.csv(kaggle_titanic,&quot;kaggle_test.csv&quot;, row.names = FALSE) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
